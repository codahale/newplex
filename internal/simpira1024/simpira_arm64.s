//go:build arm64 && !purego

#include "textflag.h"

// Precomputed round constants for Simpira-1024 (b=8, c=1..72).
// Each 16-byte entry holds the four S32 lanes: [c^b, (c^b)^0x10, (c^b)^0x20, (c^b)^0x30].
// Loading these with VLD1.P eliminates the per-step EOR+VMOV+VEOR+ADD sequence
// (4 instructions, including a cross-domain GP→NEON transfer) and replaces it with a
// single pipelined NEON load from L1, reducing µop pressure by 3 per step (216 total).
DATA roundConstants<>+0(SB)/8, $0x0000001900000009
DATA roundConstants<>+8(SB)/8, $0x0000003900000029
DATA roundConstants<>+16(SB)/8, $0x0000001a0000000a
DATA roundConstants<>+24(SB)/8, $0x0000003a0000002a
DATA roundConstants<>+32(SB)/8, $0x0000001b0000000b
DATA roundConstants<>+40(SB)/8, $0x0000003b0000002b
DATA roundConstants<>+48(SB)/8, $0x0000001c0000000c
DATA roundConstants<>+56(SB)/8, $0x0000003c0000002c
DATA roundConstants<>+64(SB)/8, $0x0000001d0000000d
DATA roundConstants<>+72(SB)/8, $0x0000003d0000002d
DATA roundConstants<>+80(SB)/8, $0x0000001e0000000e
DATA roundConstants<>+88(SB)/8, $0x0000003e0000002e
DATA roundConstants<>+96(SB)/8, $0x0000001f0000000f
DATA roundConstants<>+104(SB)/8, $0x0000003f0000002f
DATA roundConstants<>+112(SB)/8, $0x0000001000000000
DATA roundConstants<>+120(SB)/8, $0x0000003000000020
DATA roundConstants<>+128(SB)/8, $0x0000001100000001
DATA roundConstants<>+136(SB)/8, $0x0000003100000021
DATA roundConstants<>+144(SB)/8, $0x0000001200000002
DATA roundConstants<>+152(SB)/8, $0x0000003200000022
DATA roundConstants<>+160(SB)/8, $0x0000001300000003
DATA roundConstants<>+168(SB)/8, $0x0000003300000023
DATA roundConstants<>+176(SB)/8, $0x0000001400000004
DATA roundConstants<>+184(SB)/8, $0x0000003400000024
DATA roundConstants<>+192(SB)/8, $0x0000001500000005
DATA roundConstants<>+200(SB)/8, $0x0000003500000025
DATA roundConstants<>+208(SB)/8, $0x0000001600000006
DATA roundConstants<>+216(SB)/8, $0x0000003600000026
DATA roundConstants<>+224(SB)/8, $0x0000001700000007
DATA roundConstants<>+232(SB)/8, $0x0000003700000027
DATA roundConstants<>+240(SB)/8, $0x0000000800000018
DATA roundConstants<>+248(SB)/8, $0x0000002800000038
DATA roundConstants<>+256(SB)/8, $0x0000000900000019
DATA roundConstants<>+264(SB)/8, $0x0000002900000039
DATA roundConstants<>+272(SB)/8, $0x0000000a0000001a
DATA roundConstants<>+280(SB)/8, $0x0000002a0000003a
DATA roundConstants<>+288(SB)/8, $0x0000000b0000001b
DATA roundConstants<>+296(SB)/8, $0x0000002b0000003b
DATA roundConstants<>+304(SB)/8, $0x0000000c0000001c
DATA roundConstants<>+312(SB)/8, $0x0000002c0000003c
DATA roundConstants<>+320(SB)/8, $0x0000000d0000001d
DATA roundConstants<>+328(SB)/8, $0x0000002d0000003d
DATA roundConstants<>+336(SB)/8, $0x0000000e0000001e
DATA roundConstants<>+344(SB)/8, $0x0000002e0000003e
DATA roundConstants<>+352(SB)/8, $0x0000000f0000001f
DATA roundConstants<>+360(SB)/8, $0x0000002f0000003f
DATA roundConstants<>+368(SB)/8, $0x0000000000000010
DATA roundConstants<>+376(SB)/8, $0x0000002000000030
DATA roundConstants<>+384(SB)/8, $0x0000000100000011
DATA roundConstants<>+392(SB)/8, $0x0000002100000031
DATA roundConstants<>+400(SB)/8, $0x0000000200000012
DATA roundConstants<>+408(SB)/8, $0x0000002200000032
DATA roundConstants<>+416(SB)/8, $0x0000000300000013
DATA roundConstants<>+424(SB)/8, $0x0000002300000033
DATA roundConstants<>+432(SB)/8, $0x0000000400000014
DATA roundConstants<>+440(SB)/8, $0x0000002400000034
DATA roundConstants<>+448(SB)/8, $0x0000000500000015
DATA roundConstants<>+456(SB)/8, $0x0000002500000035
DATA roundConstants<>+464(SB)/8, $0x0000000600000016
DATA roundConstants<>+472(SB)/8, $0x0000002600000036
DATA roundConstants<>+480(SB)/8, $0x0000000700000017
DATA roundConstants<>+488(SB)/8, $0x0000002700000037
DATA roundConstants<>+496(SB)/8, $0x0000003800000028
DATA roundConstants<>+504(SB)/8, $0x0000001800000008
DATA roundConstants<>+512(SB)/8, $0x0000003900000029
DATA roundConstants<>+520(SB)/8, $0x0000001900000009
DATA roundConstants<>+528(SB)/8, $0x0000003a0000002a
DATA roundConstants<>+536(SB)/8, $0x0000001a0000000a
DATA roundConstants<>+544(SB)/8, $0x0000003b0000002b
DATA roundConstants<>+552(SB)/8, $0x0000001b0000000b
DATA roundConstants<>+560(SB)/8, $0x0000003c0000002c
DATA roundConstants<>+568(SB)/8, $0x0000001c0000000c
DATA roundConstants<>+576(SB)/8, $0x0000003d0000002d
DATA roundConstants<>+584(SB)/8, $0x0000001d0000000d
DATA roundConstants<>+592(SB)/8, $0x0000003e0000002e
DATA roundConstants<>+600(SB)/8, $0x0000001e0000000e
DATA roundConstants<>+608(SB)/8, $0x0000003f0000002f
DATA roundConstants<>+616(SB)/8, $0x0000001f0000000f
DATA roundConstants<>+624(SB)/8, $0x0000003000000020
DATA roundConstants<>+632(SB)/8, $0x0000001000000000
DATA roundConstants<>+640(SB)/8, $0x0000003100000021
DATA roundConstants<>+648(SB)/8, $0x0000001100000001
DATA roundConstants<>+656(SB)/8, $0x0000003200000022
DATA roundConstants<>+664(SB)/8, $0x0000001200000002
DATA roundConstants<>+672(SB)/8, $0x0000003300000023
DATA roundConstants<>+680(SB)/8, $0x0000001300000003
DATA roundConstants<>+688(SB)/8, $0x0000003400000024
DATA roundConstants<>+696(SB)/8, $0x0000001400000004
DATA roundConstants<>+704(SB)/8, $0x0000003500000025
DATA roundConstants<>+712(SB)/8, $0x0000001500000005
DATA roundConstants<>+720(SB)/8, $0x0000003600000026
DATA roundConstants<>+728(SB)/8, $0x0000001600000006
DATA roundConstants<>+736(SB)/8, $0x0000003700000027
DATA roundConstants<>+744(SB)/8, $0x0000001700000007
DATA roundConstants<>+752(SB)/8, $0x0000002800000038
DATA roundConstants<>+760(SB)/8, $0x0000000800000018
DATA roundConstants<>+768(SB)/8, $0x0000002900000039
DATA roundConstants<>+776(SB)/8, $0x0000000900000019
DATA roundConstants<>+784(SB)/8, $0x0000002a0000003a
DATA roundConstants<>+792(SB)/8, $0x0000000a0000001a
DATA roundConstants<>+800(SB)/8, $0x0000002b0000003b
DATA roundConstants<>+808(SB)/8, $0x0000000b0000001b
DATA roundConstants<>+816(SB)/8, $0x0000002c0000003c
DATA roundConstants<>+824(SB)/8, $0x0000000c0000001c
DATA roundConstants<>+832(SB)/8, $0x0000002d0000003d
DATA roundConstants<>+840(SB)/8, $0x0000000d0000001d
DATA roundConstants<>+848(SB)/8, $0x0000002e0000003e
DATA roundConstants<>+856(SB)/8, $0x0000000e0000001e
DATA roundConstants<>+864(SB)/8, $0x0000002f0000003f
DATA roundConstants<>+872(SB)/8, $0x0000000f0000001f
DATA roundConstants<>+880(SB)/8, $0x0000002000000030
DATA roundConstants<>+888(SB)/8, $0x0000000000000010
DATA roundConstants<>+896(SB)/8, $0x0000002100000031
DATA roundConstants<>+904(SB)/8, $0x0000000100000011
DATA roundConstants<>+912(SB)/8, $0x0000002200000032
DATA roundConstants<>+920(SB)/8, $0x0000000200000012
DATA roundConstants<>+928(SB)/8, $0x0000002300000033
DATA roundConstants<>+936(SB)/8, $0x0000000300000013
DATA roundConstants<>+944(SB)/8, $0x0000002400000034
DATA roundConstants<>+952(SB)/8, $0x0000000400000014
DATA roundConstants<>+960(SB)/8, $0x0000002500000035
DATA roundConstants<>+968(SB)/8, $0x0000000500000015
DATA roundConstants<>+976(SB)/8, $0x0000002600000036
DATA roundConstants<>+984(SB)/8, $0x0000000600000016
DATA roundConstants<>+992(SB)/8, $0x0000002700000037
DATA roundConstants<>+1000(SB)/8, $0x0000000700000017
DATA roundConstants<>+1008(SB)/8, $0x0000005800000048
DATA roundConstants<>+1016(SB)/8, $0x0000007800000068
DATA roundConstants<>+1024(SB)/8, $0x0000005900000049
DATA roundConstants<>+1032(SB)/8, $0x0000007900000069
DATA roundConstants<>+1040(SB)/8, $0x0000005a0000004a
DATA roundConstants<>+1048(SB)/8, $0x0000007a0000006a
DATA roundConstants<>+1056(SB)/8, $0x0000005b0000004b
DATA roundConstants<>+1064(SB)/8, $0x0000007b0000006b
DATA roundConstants<>+1072(SB)/8, $0x0000005c0000004c
DATA roundConstants<>+1080(SB)/8, $0x0000007c0000006c
DATA roundConstants<>+1088(SB)/8, $0x0000005d0000004d
DATA roundConstants<>+1096(SB)/8, $0x0000007d0000006d
DATA roundConstants<>+1104(SB)/8, $0x0000005e0000004e
DATA roundConstants<>+1112(SB)/8, $0x0000007e0000006e
DATA roundConstants<>+1120(SB)/8, $0x0000005f0000004f
DATA roundConstants<>+1128(SB)/8, $0x0000007f0000006f
DATA roundConstants<>+1136(SB)/8, $0x0000005000000040
DATA roundConstants<>+1144(SB)/8, $0x0000007000000060
GLOBL roundConstants<>(SB), RODATA|NOPTR, $1152

// SIMPIRA_STEP performs one Feistel step: dst ^= AES(AES(src, 0), rc).
// The round constant is loaded from the precomputed table via VLD1.P,
// eliminating the GP→NEON cross-domain transfer from the critical path.
#define SIMPIRA_STEP(src, dst, zero, rc, t) \
	VLD1.P 16(R1), [rc.B16]; \
	VORR src.B16, src.B16, t.B16; \
	AESE zero.B16, t.B16; \
	AESMC t.B16, t.B16; \
	AESE rc.B16, t.B16; \
	AESMC t.B16, t.B16; \
	VEOR t.B16, dst.B16, dst.B16

// func permute(state *[128]byte)
TEXT ·permute(SB), NOSPLIT, $0
	MOVD state+0(FP), R0

	VLD1.P 64(R0), [V0.B16, V1.B16, V2.B16, V3.B16]
	VLD1 (R0), [V4.B16, V5.B16, V6.B16, V7.B16]

	VEOR V16.B16, V16.B16, V16.B16
	MOVD $roundConstants<>(SB), R1

	SIMPIRA_STEP(V0, V1, V16, V17, V18)
	SIMPIRA_STEP(V2, V3, V16, V17, V18)
	SIMPIRA_STEP(V4, V5, V16, V17, V18)
	SIMPIRA_STEP(V6, V7, V16, V17, V18)

	SIMPIRA_STEP(V1, V6, V16, V17, V18)
	SIMPIRA_STEP(V7, V0, V16, V17, V18)
	SIMPIRA_STEP(V3, V4, V16, V17, V18)
	SIMPIRA_STEP(V5, V2, V16, V17, V18)

	SIMPIRA_STEP(V6, V5, V16, V17, V18)
	SIMPIRA_STEP(V2, V1, V16, V17, V18)
	SIMPIRA_STEP(V0, V3, V16, V17, V18)
	SIMPIRA_STEP(V4, V7, V16, V17, V18)

	SIMPIRA_STEP(V5, V4, V16, V17, V18)
	SIMPIRA_STEP(V7, V6, V16, V17, V18)
	SIMPIRA_STEP(V1, V0, V16, V17, V18)
	SIMPIRA_STEP(V3, V2, V16, V17, V18)

	SIMPIRA_STEP(V4, V3, V16, V17, V18)
	SIMPIRA_STEP(V2, V5, V16, V17, V18)
	SIMPIRA_STEP(V6, V1, V16, V17, V18)
	SIMPIRA_STEP(V0, V7, V16, V17, V18)

	SIMPIRA_STEP(V3, V0, V16, V17, V18)
	SIMPIRA_STEP(V7, V4, V16, V17, V18)
	SIMPIRA_STEP(V5, V6, V16, V17, V18)
	SIMPIRA_STEP(V1, V2, V16, V17, V18)

	SIMPIRA_STEP(V0, V1, V16, V17, V18)
	SIMPIRA_STEP(V2, V3, V16, V17, V18)
	SIMPIRA_STEP(V4, V5, V16, V17, V18)
	SIMPIRA_STEP(V6, V7, V16, V17, V18)

	SIMPIRA_STEP(V1, V6, V16, V17, V18)
	SIMPIRA_STEP(V7, V0, V16, V17, V18)
	SIMPIRA_STEP(V3, V4, V16, V17, V18)
	SIMPIRA_STEP(V5, V2, V16, V17, V18)

	SIMPIRA_STEP(V6, V5, V16, V17, V18)
	SIMPIRA_STEP(V2, V1, V16, V17, V18)
	SIMPIRA_STEP(V0, V3, V16, V17, V18)
	SIMPIRA_STEP(V4, V7, V16, V17, V18)

	SIMPIRA_STEP(V5, V4, V16, V17, V18)
	SIMPIRA_STEP(V7, V6, V16, V17, V18)
	SIMPIRA_STEP(V1, V0, V16, V17, V18)
	SIMPIRA_STEP(V3, V2, V16, V17, V18)

	SIMPIRA_STEP(V4, V3, V16, V17, V18)
	SIMPIRA_STEP(V2, V5, V16, V17, V18)
	SIMPIRA_STEP(V6, V1, V16, V17, V18)
	SIMPIRA_STEP(V0, V7, V16, V17, V18)

	SIMPIRA_STEP(V3, V0, V16, V17, V18)
	SIMPIRA_STEP(V7, V4, V16, V17, V18)
	SIMPIRA_STEP(V5, V6, V16, V17, V18)
	SIMPIRA_STEP(V1, V2, V16, V17, V18)

	SIMPIRA_STEP(V0, V1, V16, V17, V18)
	SIMPIRA_STEP(V2, V3, V16, V17, V18)
	SIMPIRA_STEP(V4, V5, V16, V17, V18)
	SIMPIRA_STEP(V6, V7, V16, V17, V18)

	SIMPIRA_STEP(V1, V6, V16, V17, V18)
	SIMPIRA_STEP(V7, V0, V16, V17, V18)
	SIMPIRA_STEP(V3, V4, V16, V17, V18)
	SIMPIRA_STEP(V5, V2, V16, V17, V18)

	SIMPIRA_STEP(V6, V5, V16, V17, V18)
	SIMPIRA_STEP(V2, V1, V16, V17, V18)
	SIMPIRA_STEP(V0, V3, V16, V17, V18)
	SIMPIRA_STEP(V4, V7, V16, V17, V18)

	SIMPIRA_STEP(V5, V4, V16, V17, V18)
	SIMPIRA_STEP(V7, V6, V16, V17, V18)
	SIMPIRA_STEP(V1, V0, V16, V17, V18)
	SIMPIRA_STEP(V3, V2, V16, V17, V18)

	SIMPIRA_STEP(V4, V3, V16, V17, V18)
	SIMPIRA_STEP(V2, V5, V16, V17, V18)
	SIMPIRA_STEP(V6, V1, V16, V17, V18)
	SIMPIRA_STEP(V0, V7, V16, V17, V18)

	SIMPIRA_STEP(V3, V0, V16, V17, V18)
	SIMPIRA_STEP(V7, V4, V16, V17, V18)
	SIMPIRA_STEP(V5, V6, V16, V17, V18)
	SIMPIRA_STEP(V1, V2, V16, V17, V18)

	MOVD state+0(FP), R0
	VST1.P [V0.B16, V1.B16, V2.B16, V3.B16], 64(R0)
	VST1 [V4.B16, V5.B16, V6.B16, V7.B16], (R0)
	RET
